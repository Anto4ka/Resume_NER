{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair_nlp_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jloutz/Resume_NER/blob/master/flair_nlp_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF_9MAOKPyAY",
        "colab_type": "text"
      },
      "source": [
        "Resume NER Part 4: Working with Flair NLP\n",
        "\n",
        "---\n",
        "\n",
        "In this part we will use flair NLP to train a model on our data and evaluate the results. Please make sure you have set up your Google account and uploaded your files to Google drive. This Notebook should run on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXoVFeGlQdEu",
        "colab_type": "text"
      },
      "source": [
        "Let's change the working directory to the Google drive where our training data is, and install flair nlp. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zuCubbF-AQc",
        "colab_type": "code",
        "outputId": "627d99c3-3b9e-4ec8-c3a0-32fd20284ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXiOU9ihIHvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/SAKI_2019/dataset\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8542ZPSnM_d",
        "colab_type": "code",
        "outputId": "e6ce8719-4410-4f33-882f-0df22ae0b78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1340
        }
      },
      "source": [
        "# download flair library #\n",
        "! pip install flair"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Collecting regex (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.6MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Collecting bpemb>=0.2.9 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.16.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.3.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.165)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
            "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.165 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.165)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "Building wheels for collected packages: sqlitedict, regex, mpld3, segtok\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "Successfully built sqlitedict regex mpld3 segtok\n",
            "Installing collected packages: sqlitedict, regex, mpld3, pytorch-pretrained-bert, segtok, sentencepiece, bpemb, deprecated, flair\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOWwKlH8QwBU",
        "colab_type": "text"
      },
      "source": [
        "In the next section, we will train a NER model with flair. This code is taken from the flair nlp tutorials section 7. \"Training a model\" \n",
        "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghp5-JZTRYOb",
        "colab_type": "code",
        "outputId": "4b57c810-986e-49ff-bb2a-4413602744b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# imports \n",
        "from flair.datasets import Corpus\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "\n",
        "## make sure this describes your file structure\n",
        "columns = {0: 'text', 2: \"ner\"}\n",
        "\n",
        "# folder where training and test data are\n",
        "data_folder = '/content/gdrive/My Drive/SAKI_2019/dataset/flair'\n",
        "\n",
        "# 1.0 is full data, try a much smaller number like 0.1 to test run the code\n",
        "downsample = 1.0 \n",
        "\n",
        "## your train file name\n",
        "train_file = 'bilou_training.csv'\n",
        "\n",
        "## your test file name\n",
        "test_file = 'bilou_test.csv'\n",
        "# 1. get the corpus\n",
        "corpus: Corpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
        "                                                             train_file=train_file,\n",
        "                                                             test_file=test_file,\n",
        "                                                           dev_file=None).downsample(downsample)\n",
        "print(corpus)\n",
        "print(len(corpus.train))\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type='ner')\n",
        "print(tag_dictionary.idx2item)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:11,728 Reading data from /content/gdrive/My Drive/SAKI_2019/dataset/flair\n",
            "2019-06-17 10:48:11,729 Train: /content/gdrive/My Drive/SAKI_2019/dataset/flair/bilou_training.csv\n",
            "2019-06-17 10:48:11,734 Dev: None\n",
            "2019-06-17 10:48:11,736 Test: /content/gdrive/My Drive/SAKI_2019/dataset/flair/bilou_test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated function (or staticmethod) load_column_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:312: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  train_file, column_format\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:318: DeprecationWarning: Call to deprecated function (or staticmethod) read_column_data. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  test_file, column_format\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Corpus: 493 train + 55 dev + 137 test sentences\n",
            "493\n",
            "[b'<unk>', b'O', b'U-Location', b'', b'U-Skills', b'U-Degree', b'B-Skills', b'I-Skills', b'L-Skills', b'B-Degree', b'I-Degree', b'L-Degree', b'-', b'B-Location', b'L-Location', b'I-Location', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6H1IzUbR5iH",
        "colab_type": "code",
        "outputId": "b6919a63-97de-428b-c701-29e8bf6a18a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "\n",
        "# 4. initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings,FlairEmbeddings\n",
        "from typing import List\n",
        "\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('glove'),\n",
        "    # comment in this line to use character embeddings\n",
        "    # CharacterEmbeddings(),\n",
        "\n",
        "    # comment in these lines to use flair embeddings (needs a LONG time to train :-)\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type='ner',\n",
        "                                        use_crf=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:19,307 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpywwxpos0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:08<00:00, 19665524.70B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:28,014 copying /tmp/tmpywwxpos0 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:28,284 removing temp file /tmp/tmpywwxpos0\n",
            "2019-06-17 10:48:28,777 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpnhczj7kf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 11945486.72B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:31,110 copying /tmp/tmpnhczj7kf to cache at /root/.flair/embeddings/glove.gensim\n",
            "2019-06-17 10:48:31,136 removing temp file /tmp/tmpnhczj7kf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:33,172 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpruv2pxu9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:04<00:00, 16110576.39B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:38,246 copying /tmp/tmpruv2pxu9 to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:38,366 removing temp file /tmp/tmpruv2pxu9\n",
            "2019-06-17 10:48:46,665 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmptc94jmoq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034575/73034575 [00:04<00:00, 16635714.23B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:51,644 copying /tmp/tmptc94jmoq to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:51,741 removing temp file /tmp/tmptc94jmoq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMA2qsyTvHq",
        "colab_type": "code",
        "outputId": "5ea35d66-7407-4df5-9a66-1d654d1e4b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9482
        }
      },
      "source": [
        "# 6. initialize trainer\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "## give your model a name and folder of your choice. Your model will be saved there for loading later \n",
        "## you can run this notebook many times with different embeddings/params and save the models with different names\n",
        "model_name = 'resources/taggers/resume-ner-4'\n",
        "\n",
        "# 7. start training - you can experiment with batch size if you get memory errors\n",
        "# how many epochs does it take before the model stops showing improvement? Start with a big number like 150, and stop the code cell\n",
        "# from running at any time - the framework will persist the best model even if you interrupt training. \n",
        "trainer.train(model_name,\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=5,\n",
        "              #anneal_with_restarts=True,\n",
        "              max_epochs=150)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-17 10:48:53,618 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:48:53,623 Evaluation method: MICRO_F1_SCORE\n",
            "2019-06-17 10:48:54,864 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 10:49:06,685 epoch 1 - iter 0/99 - loss 2706.55908203\n",
            "2019-06-17 10:50:32,402 epoch 1 - iter 9/99 - loss 693.45689697\n",
            "2019-06-17 10:51:40,253 epoch 1 - iter 18/99 - loss 488.24582190\n",
            "2019-06-17 10:53:12,777 epoch 1 - iter 27/99 - loss 415.98351479\n",
            "2019-06-17 10:54:19,619 epoch 1 - iter 36/99 - loss 376.00188962\n",
            "2019-06-17 10:55:48,450 epoch 1 - iter 45/99 - loss 355.31663314\n",
            "2019-06-17 10:57:24,910 epoch 1 - iter 54/99 - loss 332.68958893\n",
            "2019-06-17 10:58:45,664 epoch 1 - iter 63/99 - loss 314.93679237\n",
            "2019-06-17 11:00:08,052 epoch 1 - iter 72/99 - loss 298.24884660\n",
            "2019-06-17 11:01:38,558 epoch 1 - iter 81/99 - loss 283.27220749\n",
            "2019-06-17 11:03:04,002 epoch 1 - iter 90/99 - loss 268.44819624\n",
            "2019-06-17 11:04:25,439 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:04:25,441 EPOCH 1 done: loss 262.1703 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 11:06:10,724 DEV : loss 194.6061248779297 - score 0.0158\n",
            "2019-06-17 11:10:04,579 TEST : loss 186.0718231201172 - score 0.0274\n",
            "2019-06-17 11:10:11,371 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:10:18,939 epoch 2 - iter 0/99 - loss 165.07922363\n",
            "2019-06-17 11:11:41,873 epoch 2 - iter 9/99 - loss 162.42099915\n",
            "2019-06-17 11:13:04,026 epoch 2 - iter 18/99 - loss 145.54432196\n",
            "2019-06-17 11:14:17,068 epoch 2 - iter 27/99 - loss 173.41175692\n",
            "2019-06-17 11:15:51,147 epoch 2 - iter 36/99 - loss 166.06287178\n",
            "2019-06-17 11:17:19,174 epoch 2 - iter 45/99 - loss 154.04346350\n",
            "2019-06-17 11:18:49,488 epoch 2 - iter 54/99 - loss 147.23861861\n",
            "2019-06-17 11:20:29,924 epoch 2 - iter 63/99 - loss 142.72212464\n",
            "2019-06-17 11:22:11,853 epoch 2 - iter 72/99 - loss 141.71217984\n",
            "2019-06-17 11:23:41,488 epoch 2 - iter 81/99 - loss 137.01069613\n",
            "2019-06-17 11:24:51,767 epoch 2 - iter 90/99 - loss 133.15167006\n",
            "2019-06-17 11:26:13,210 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:26:13,212 EPOCH 2 done: loss 134.0317 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 11:28:01,631 DEV : loss 87.12171173095703 - score 0.0876\n",
            "2019-06-17 11:31:55,557 TEST : loss 81.70572662353516 - score 0.1563\n",
            "2019-06-17 11:32:00,701 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:32:17,876 epoch 3 - iter 0/99 - loss 78.15315247\n",
            "2019-06-17 11:34:07,986 epoch 3 - iter 9/99 - loss 124.42570305\n",
            "2019-06-17 11:35:38,804 epoch 3 - iter 18/99 - loss 134.78376087\n",
            "2019-06-17 11:37:02,766 epoch 3 - iter 27/99 - loss 118.98520974\n",
            "2019-06-17 11:38:19,037 epoch 3 - iter 36/99 - loss 117.64178405\n",
            "2019-06-17 11:39:38,584 epoch 3 - iter 45/99 - loss 115.35529319\n",
            "2019-06-17 11:41:05,948 epoch 3 - iter 54/99 - loss 112.38918970\n",
            "2019-06-17 11:42:45,988 epoch 3 - iter 63/99 - loss 112.96077877\n",
            "2019-06-17 11:44:02,178 epoch 3 - iter 72/99 - loss 111.60942015\n",
            "2019-06-17 11:45:31,258 epoch 3 - iter 81/99 - loss 110.99699272\n",
            "2019-06-17 11:47:00,694 epoch 3 - iter 90/99 - loss 112.59441535\n",
            "2019-06-17 11:48:11,350 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:48:11,352 EPOCH 3 done: loss 116.8836 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 11:49:58,951 DEV : loss 85.15070343017578 - score 0.0691\n",
            "2019-06-17 11:53:50,688 TEST : loss 72.20933532714844 - score 0.1428\n",
            "2019-06-17 11:53:50,695 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 11:54:05,032 epoch 4 - iter 0/99 - loss 117.30028534\n",
            "2019-06-17 11:55:41,297 epoch 4 - iter 9/99 - loss 107.94051132\n",
            "2019-06-17 11:57:16,094 epoch 4 - iter 18/99 - loss 101.49183233\n",
            "2019-06-17 11:58:47,717 epoch 4 - iter 27/99 - loss 102.86034414\n",
            "2019-06-17 12:00:05,106 epoch 4 - iter 36/99 - loss 97.75723602\n",
            "2019-06-17 12:01:28,703 epoch 4 - iter 45/99 - loss 100.84773018\n",
            "2019-06-17 12:02:51,174 epoch 4 - iter 54/99 - loss 98.48449405\n",
            "2019-06-17 12:04:04,094 epoch 4 - iter 63/99 - loss 93.63291869\n",
            "2019-06-17 12:05:25,619 epoch 4 - iter 72/99 - loss 91.24635999\n",
            "2019-06-17 12:07:09,171 epoch 4 - iter 81/99 - loss 90.88333786\n",
            "2019-06-17 12:08:39,782 epoch 4 - iter 90/99 - loss 90.18167437\n",
            "2019-06-17 12:09:49,670 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:09:49,672 EPOCH 4 done: loss 90.1224 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 12:11:37,500 DEV : loss 67.317626953125 - score 0.1312\n",
            "2019-06-17 12:15:29,578 TEST : loss 57.53987503051758 - score 0.2344\n",
            "2019-06-17 12:15:34,535 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:15:52,178 epoch 5 - iter 0/99 - loss 72.62023926\n",
            "2019-06-17 12:17:22,181 epoch 5 - iter 9/99 - loss 76.46104584\n",
            "2019-06-17 12:18:59,928 epoch 5 - iter 18/99 - loss 92.70549413\n",
            "2019-06-17 12:20:13,307 epoch 5 - iter 27/99 - loss 90.97126893\n",
            "2019-06-17 12:21:47,535 epoch 5 - iter 36/99 - loss 92.37552617\n",
            "2019-06-17 12:23:28,072 epoch 5 - iter 45/99 - loss 92.63144506\n",
            "2019-06-17 12:24:33,781 epoch 5 - iter 54/99 - loss 88.69650789\n",
            "2019-06-17 12:26:03,638 epoch 5 - iter 63/99 - loss 87.31984901\n",
            "2019-06-17 12:27:19,101 epoch 5 - iter 72/99 - loss 86.58675121\n",
            "2019-06-17 12:28:32,646 epoch 5 - iter 81/99 - loss 84.22626856\n",
            "2019-06-17 12:29:46,055 epoch 5 - iter 90/99 - loss 83.80495577\n",
            "2019-06-17 12:30:56,346 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:30:56,348 EPOCH 5 done: loss 82.4546 - lr 0.1000 - bad epochs 0\n",
            "2019-06-17 12:32:44,000 DEV : loss 70.171875 - score 0.0066\n",
            "2019-06-17 12:36:36,172 TEST : loss 67.59329986572266 - score 0.0085\n",
            "2019-06-17 12:36:36,181 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:36:42,046 epoch 6 - iter 0/99 - loss 63.56697464\n",
            "2019-06-17 12:38:10,924 epoch 6 - iter 9/99 - loss 77.24699249\n",
            "2019-06-17 12:39:24,078 epoch 6 - iter 18/99 - loss 75.50420922\n",
            "2019-06-17 12:41:02,911 epoch 6 - iter 27/99 - loss 90.01196044\n",
            "2019-06-17 12:42:26,226 epoch 6 - iter 36/99 - loss 90.84859879\n",
            "2019-06-17 12:44:03,826 epoch 6 - iter 45/99 - loss 90.22007312\n",
            "2019-06-17 12:45:14,588 epoch 6 - iter 54/99 - loss 88.37055518\n",
            "2019-06-17 12:47:08,730 epoch 6 - iter 63/99 - loss 93.95158345\n",
            "2019-06-17 12:48:15,506 epoch 6 - iter 72/99 - loss 90.21725832\n",
            "2019-06-17 12:49:35,196 epoch 6 - iter 81/99 - loss 86.89278986\n",
            "2019-06-17 12:51:25,650 epoch 6 - iter 90/99 - loss 85.55407893\n",
            "2019-06-17 12:52:35,490 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:52:35,492 EPOCH 6 done: loss 84.6930 - lr 0.1000 - bad epochs 1\n",
            "2019-06-17 12:54:23,264 DEV : loss 65.5458984375 - score 0.0585\n",
            "2019-06-17 12:58:12,847 TEST : loss 67.36453247070312 - score 0.1299\n",
            "2019-06-17 12:58:12,856 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 12:58:32,908 epoch 7 - iter 0/99 - loss 94.49912262\n",
            "2019-06-17 13:00:07,874 epoch 7 - iter 9/99 - loss 65.94407349\n",
            "2019-06-17 13:01:31,105 epoch 7 - iter 18/99 - loss 61.85338010\n",
            "2019-06-17 13:02:42,585 epoch 7 - iter 27/99 - loss 63.49980674\n",
            "2019-06-17 13:04:10,661 epoch 7 - iter 36/99 - loss 62.12333808\n",
            "2019-06-17 13:05:49,025 epoch 7 - iter 45/99 - loss 67.28093848\n",
            "2019-06-17 13:07:17,952 epoch 7 - iter 54/99 - loss 67.92081947\n",
            "2019-06-17 13:08:26,168 epoch 7 - iter 63/99 - loss 65.89283139\n",
            "2019-06-17 13:09:41,183 epoch 7 - iter 72/99 - loss 66.78417671\n",
            "2019-06-17 13:11:00,766 epoch 7 - iter 81/99 - loss 69.31665755\n",
            "2019-06-17 13:12:28,589 epoch 7 - iter 90/99 - loss 69.98327327\n",
            "2019-06-17 13:13:53,850 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 13:13:53,852 EPOCH 7 done: loss 70.3226 - lr 0.1000 - bad epochs 2\n",
            "2019-06-17 13:15:41,440 DEV : loss 53.82754898071289 - score 0.0798\n",
            "2019-06-17 13:19:31,122 TEST : loss 48.29483413696289 - score 0.2296\n",
            "2019-06-17 13:19:31,131 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 13:19:38,669 epoch 8 - iter 0/99 - loss 34.13615799\n",
            "2019-06-17 13:20:58,876 epoch 8 - iter 9/99 - loss 52.61923294\n",
            "2019-06-17 13:22:14,498 epoch 8 - iter 18/99 - loss 55.64105727\n",
            "2019-06-17 13:23:44,948 epoch 8 - iter 27/99 - loss 60.70288372\n",
            "2019-06-17 13:25:10,388 epoch 8 - iter 36/99 - loss 60.24101288\n",
            "2019-06-17 13:26:44,496 epoch 8 - iter 45/99 - loss 63.02794622\n",
            "2019-06-17 13:28:25,984 epoch 8 - iter 54/99 - loss 67.80320310\n",
            "2019-06-17 13:29:48,478 epoch 8 - iter 63/99 - loss 66.23685801\n",
            "2019-06-17 13:31:29,392 epoch 8 - iter 72/99 - loss 67.45325804\n",
            "2019-06-17 13:32:37,540 epoch 8 - iter 81/99 - loss 67.31785958\n",
            "2019-06-17 13:34:18,565 epoch 8 - iter 90/99 - loss 68.83634615\n",
            "2019-06-17 13:35:15,046 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 13:35:15,051 EPOCH 8 done: loss 67.1449 - lr 0.1000 - bad epochs 3\n",
            "2019-06-17 13:37:02,729 DEV : loss 180.78631591796875 - score 0.1023\n",
            "2019-06-17 13:40:52,908 TEST : loss 183.6693878173828 - score 0.1495\n",
            "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-06-17 13:40:52,918 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 13:41:09,442 epoch 9 - iter 0/99 - loss 178.53269958\n",
            "2019-06-17 13:42:51,661 epoch 9 - iter 9/99 - loss 76.81377258\n",
            "2019-06-17 13:44:01,302 epoch 9 - iter 18/99 - loss 63.04243469\n",
            "2019-06-17 13:45:08,509 epoch 9 - iter 27/99 - loss 57.15550675\n",
            "2019-06-17 13:46:31,487 epoch 9 - iter 36/99 - loss 53.97056910\n",
            "2019-06-17 13:47:54,755 epoch 9 - iter 45/99 - loss 55.74629775\n",
            "2019-06-17 13:49:15,181 epoch 9 - iter 54/99 - loss 55.36265172\n",
            "2019-06-17 13:50:57,384 epoch 9 - iter 63/99 - loss 54.48872644\n",
            "2019-06-17 13:52:27,596 epoch 9 - iter 72/99 - loss 54.27724397\n",
            "2019-06-17 13:53:55,682 epoch 9 - iter 81/99 - loss 53.57749257\n",
            "2019-06-17 13:55:21,203 epoch 9 - iter 90/99 - loss 53.92561703\n",
            "2019-06-17 13:56:38,765 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 13:56:38,766 EPOCH 9 done: loss 53.2871 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 13:58:26,813 DEV : loss 50.9842643737793 - score 0.131\n",
            "2019-06-17 14:02:16,859 TEST : loss 44.5097541809082 - score 0.2286\n",
            "2019-06-17 14:02:16,869 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 14:02:25,410 epoch 10 - iter 0/99 - loss 40.68639755\n",
            "2019-06-17 14:03:59,461 epoch 10 - iter 9/99 - loss 52.86444492\n",
            "2019-06-17 14:05:36,481 epoch 10 - iter 18/99 - loss 51.31779761\n",
            "2019-06-17 14:06:52,617 epoch 10 - iter 27/99 - loss 48.91394329\n",
            "2019-06-17 14:08:25,846 epoch 10 - iter 36/99 - loss 50.39304084\n",
            "2019-06-17 14:09:43,933 epoch 10 - iter 45/99 - loss 48.82010327\n",
            "2019-06-17 14:10:54,969 epoch 10 - iter 54/99 - loss 48.63734606\n",
            "2019-06-17 14:12:06,694 epoch 10 - iter 63/99 - loss 47.43754116\n",
            "2019-06-17 14:13:54,616 epoch 10 - iter 72/99 - loss 47.18687745\n",
            "2019-06-17 14:15:39,182 epoch 10 - iter 81/99 - loss 46.93078874\n",
            "2019-06-17 14:17:16,620 epoch 10 - iter 90/99 - loss 47.10370395\n",
            "2019-06-17 14:18:22,171 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 14:18:22,173 EPOCH 10 done: loss 47.8321 - lr 0.0500 - bad epochs 1\n",
            "2019-06-17 14:20:07,017 DEV : loss 46.97672653198242 - score 0.3057\n",
            "2019-06-17 14:23:59,415 TEST : loss 47.695945739746094 - score 0.2749\n",
            "2019-06-17 14:24:04,293 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 14:24:21,856 epoch 11 - iter 0/99 - loss 81.19341278\n",
            "2019-06-17 14:25:46,778 epoch 11 - iter 9/99 - loss 49.88903275\n",
            "2019-06-17 14:27:11,589 epoch 11 - iter 18/99 - loss 47.34079311\n",
            "2019-06-17 14:28:20,822 epoch 11 - iter 27/99 - loss 49.86267144\n",
            "2019-06-17 14:29:48,638 epoch 11 - iter 36/99 - loss 46.74259701\n",
            "2019-06-17 14:31:28,031 epoch 11 - iter 45/99 - loss 46.62519368\n",
            "2019-06-17 14:33:03,559 epoch 11 - iter 54/99 - loss 46.27728774\n",
            "2019-06-17 14:34:36,813 epoch 11 - iter 63/99 - loss 44.93768585\n",
            "2019-06-17 14:35:58,171 epoch 11 - iter 72/99 - loss 45.67004026\n",
            "2019-06-17 14:37:27,916 epoch 11 - iter 81/99 - loss 46.68449400\n",
            "2019-06-17 14:39:00,201 epoch 11 - iter 90/99 - loss 47.01784752\n",
            "2019-06-17 14:40:18,094 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 14:40:18,096 EPOCH 11 done: loss 47.3040 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 14:42:03,117 DEV : loss 41.68581008911133 - score 0.3313\n",
            "2019-06-17 14:45:55,380 TEST : loss 41.93950653076172 - score 0.3583\n",
            "2019-06-17 14:46:00,244 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 14:46:10,812 epoch 12 - iter 0/99 - loss 37.67774963\n",
            "2019-06-17 14:47:26,863 epoch 12 - iter 9/99 - loss 48.36070175\n",
            "2019-06-17 14:49:07,399 epoch 12 - iter 18/99 - loss 51.97168531\n",
            "2019-06-17 14:50:25,748 epoch 12 - iter 27/99 - loss 47.90136177\n",
            "2019-06-17 14:51:50,883 epoch 12 - iter 36/99 - loss 49.25950228\n",
            "2019-06-17 14:52:58,157 epoch 12 - iter 45/99 - loss 49.34188584\n",
            "2019-06-17 14:54:26,124 epoch 12 - iter 54/99 - loss 47.95651008\n",
            "2019-06-17 14:56:11,618 epoch 12 - iter 63/99 - loss 47.02269845\n",
            "2019-06-17 14:57:33,817 epoch 12 - iter 72/99 - loss 46.99603317\n",
            "2019-06-17 14:59:14,747 epoch 12 - iter 81/99 - loss 46.69945006\n",
            "2019-06-17 15:00:38,813 epoch 12 - iter 90/99 - loss 46.64639549\n",
            "2019-06-17 15:01:55,449 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:01:55,451 EPOCH 12 done: loss 46.3030 - lr 0.0500 - bad epochs 0\n",
            "2019-06-17 15:03:43,503 DEV : loss 43.52336120605469 - score 0.1485\n",
            "2019-06-17 15:07:35,886 TEST : loss 44.547733306884766 - score 0.2187\n",
            "2019-06-17 15:07:35,895 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:07:47,280 epoch 13 - iter 0/99 - loss 30.34162712\n",
            "2019-06-17 15:09:26,295 epoch 13 - iter 9/99 - loss 41.38500481\n",
            "2019-06-17 15:10:58,359 epoch 13 - iter 18/99 - loss 41.77705584\n",
            "2019-06-17 15:12:41,241 epoch 13 - iter 27/99 - loss 42.70484597\n",
            "2019-06-17 15:13:52,138 epoch 13 - iter 36/99 - loss 39.74255655\n",
            "2019-06-17 15:15:26,455 epoch 13 - iter 45/99 - loss 42.53589191\n",
            "2019-06-17 15:16:37,732 epoch 13 - iter 54/99 - loss 42.03952571\n",
            "2019-06-17 15:17:57,299 epoch 13 - iter 63/99 - loss 41.83525950\n",
            "2019-06-17 15:19:25,938 epoch 13 - iter 72/99 - loss 42.63464173\n",
            "2019-06-17 15:20:51,874 epoch 13 - iter 81/99 - loss 43.55251994\n",
            "2019-06-17 15:22:03,838 epoch 13 - iter 90/99 - loss 43.62973559\n",
            "2019-06-17 15:23:18,232 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:23:18,238 EPOCH 13 done: loss 45.2390 - lr 0.0500 - bad epochs 1\n",
            "2019-06-17 15:25:06,327 DEV : loss 38.834228515625 - score 0.1658\n",
            "2019-06-17 15:28:58,849 TEST : loss 38.99763870239258 - score 0.2325\n",
            "2019-06-17 15:28:58,867 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:29:20,472 epoch 14 - iter 0/99 - loss 17.92168999\n",
            "2019-06-17 15:30:56,112 epoch 14 - iter 9/99 - loss 58.33638725\n",
            "2019-06-17 15:32:20,825 epoch 14 - iter 18/99 - loss 53.03749707\n",
            "2019-06-17 15:33:34,180 epoch 14 - iter 27/99 - loss 54.60737841\n",
            "2019-06-17 15:34:56,794 epoch 14 - iter 36/99 - loss 49.28186698\n",
            "2019-06-17 15:36:10,492 epoch 14 - iter 45/99 - loss 48.14154967\n",
            "2019-06-17 15:37:32,176 epoch 14 - iter 54/99 - loss 46.96619455\n",
            "2019-06-17 15:38:51,027 epoch 14 - iter 63/99 - loss 45.55908467\n",
            "2019-06-17 15:40:21,277 epoch 14 - iter 72/99 - loss 45.68741541\n",
            "2019-06-17 15:41:46,041 epoch 14 - iter 81/99 - loss 45.27053415\n",
            "2019-06-17 15:43:35,253 epoch 14 - iter 90/99 - loss 46.13318145\n",
            "2019-06-17 15:44:56,717 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:44:56,718 EPOCH 14 done: loss 45.4515 - lr 0.0500 - bad epochs 2\n",
            "2019-06-17 15:46:44,880 DEV : loss 51.06686782836914 - score 0.122\n",
            "2019-06-17 15:50:37,969 TEST : loss 53.97079086303711 - score 0.1516\n",
            "2019-06-17 15:50:37,978 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 15:50:46,749 epoch 15 - iter 0/99 - loss 34.90832520\n",
            "2019-06-17 15:52:25,571 epoch 15 - iter 9/99 - loss 57.37719383\n",
            "2019-06-17 15:53:45,476 epoch 15 - iter 18/99 - loss 50.86837608\n",
            "2019-06-17 15:55:05,183 epoch 15 - iter 27/99 - loss 46.89260524\n",
            "2019-06-17 15:56:29,018 epoch 15 - iter 36/99 - loss 43.77559492\n",
            "2019-06-17 15:57:55,655 epoch 15 - iter 45/99 - loss 41.89987465\n",
            "2019-06-17 15:59:37,814 epoch 15 - iter 54/99 - loss 43.42840625\n",
            "2019-06-17 16:01:05,363 epoch 15 - iter 63/99 - loss 43.52814013\n",
            "2019-06-17 16:02:33,157 epoch 15 - iter 72/99 - loss 43.14946713\n",
            "2019-06-17 16:03:33,904 epoch 15 - iter 81/99 - loss 42.46663891\n",
            "2019-06-17 16:05:12,070 epoch 15 - iter 90/99 - loss 42.74642712\n",
            "2019-06-17 16:06:41,886 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:06:41,888 EPOCH 15 done: loss 43.4654 - lr 0.0500 - bad epochs 3\n",
            "2019-06-17 16:08:29,895 DEV : loss 36.868133544921875 - score 0.172\n",
            "2019-06-17 16:12:19,692 TEST : loss 35.50567626953125 - score 0.2454\n",
            "Epoch    14: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-06-17 16:12:19,702 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:12:25,766 epoch 16 - iter 0/99 - loss 23.24896240\n",
            "2019-06-17 16:13:50,937 epoch 16 - iter 9/99 - loss 34.88063622\n",
            "2019-06-17 16:15:05,609 epoch 16 - iter 18/99 - loss 36.71001334\n",
            "2019-06-17 16:16:27,391 epoch 16 - iter 27/99 - loss 38.91129841\n",
            "2019-06-17 16:17:34,729 epoch 16 - iter 36/99 - loss 39.34581808\n",
            "2019-06-17 16:19:00,929 epoch 16 - iter 45/99 - loss 40.71954984\n",
            "2019-06-17 16:20:14,670 epoch 16 - iter 54/99 - loss 39.86404702\n",
            "2019-06-17 16:21:34,658 epoch 16 - iter 63/99 - loss 39.72794214\n",
            "2019-06-17 16:23:01,701 epoch 16 - iter 72/99 - loss 39.64548095\n",
            "2019-06-17 16:24:30,519 epoch 16 - iter 81/99 - loss 39.81010886\n",
            "2019-06-17 16:26:33,380 epoch 16 - iter 90/99 - loss 39.54067519\n",
            "2019-06-17 16:27:58,326 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:27:58,328 EPOCH 16 done: loss 39.6119 - lr 0.0250 - bad epochs 0\n",
            "2019-06-17 16:29:46,362 DEV : loss 37.24627685546875 - score 0.2095\n",
            "2019-06-17 16:33:36,013 TEST : loss 35.16205978393555 - score 0.2792\n",
            "2019-06-17 16:33:36,022 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:33:44,779 epoch 17 - iter 0/99 - loss 18.74420166\n",
            "2019-06-17 16:35:37,389 epoch 17 - iter 9/99 - loss 36.35221653\n",
            "2019-06-17 16:36:49,742 epoch 17 - iter 18/99 - loss 33.32360017\n",
            "2019-06-17 16:38:13,771 epoch 17 - iter 27/99 - loss 36.53209714\n",
            "2019-06-17 16:39:47,960 epoch 17 - iter 36/99 - loss 38.07398935\n",
            "2019-06-17 16:41:05,251 epoch 17 - iter 45/99 - loss 37.77341979\n",
            "2019-06-17 16:42:29,446 epoch 17 - iter 54/99 - loss 37.48128936\n",
            "2019-06-17 16:43:48,672 epoch 17 - iter 63/99 - loss 37.63925104\n",
            "2019-06-17 16:45:15,144 epoch 17 - iter 72/99 - loss 37.59710802\n",
            "2019-06-17 16:46:27,753 epoch 17 - iter 81/99 - loss 38.10210749\n",
            "2019-06-17 16:48:15,350 epoch 17 - iter 90/99 - loss 39.16914535\n",
            "2019-06-17 16:49:22,903 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:49:22,905 EPOCH 17 done: loss 39.0042 - lr 0.0250 - bad epochs 1\n",
            "2019-06-17 16:51:10,553 DEV : loss 34.61566925048828 - score 0.2008\n",
            "2019-06-17 16:54:59,884 TEST : loss 33.82353973388672 - score 0.3977\n",
            "2019-06-17 16:54:59,898 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 16:55:05,090 epoch 18 - iter 0/99 - loss 25.03816795\n",
            "2019-06-17 16:56:27,443 epoch 18 - iter 9/99 - loss 31.20189266\n",
            "2019-06-17 16:57:43,896 epoch 18 - iter 18/99 - loss 32.67274033\n",
            "2019-06-17 16:58:52,748 epoch 18 - iter 27/99 - loss 34.13953304\n",
            "2019-06-17 17:00:29,012 epoch 18 - iter 36/99 - loss 34.04489827\n",
            "2019-06-17 17:01:44,596 epoch 18 - iter 45/99 - loss 37.73826603\n",
            "2019-06-17 17:03:23,666 epoch 18 - iter 54/99 - loss 37.98011173\n",
            "2019-06-17 17:04:53,138 epoch 18 - iter 63/99 - loss 38.37092075\n",
            "2019-06-17 17:06:38,357 epoch 18 - iter 72/99 - loss 39.32169912\n",
            "2019-06-17 17:08:07,599 epoch 18 - iter 81/99 - loss 38.66304309\n",
            "2019-06-17 17:09:35,087 epoch 18 - iter 90/99 - loss 38.04042830\n",
            "2019-06-17 17:10:48,550 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:10:48,551 EPOCH 18 done: loss 38.1881 - lr 0.0250 - bad epochs 2\n",
            "2019-06-17 17:12:36,263 DEV : loss 33.48101806640625 - score 0.4298\n",
            "2019-06-17 17:16:25,806 TEST : loss 34.26203918457031 - score 0.3925\n",
            "2019-06-17 17:16:31,035 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:16:37,781 epoch 19 - iter 0/99 - loss 33.75405884\n",
            "2019-06-17 17:18:04,817 epoch 19 - iter 9/99 - loss 35.32481327\n",
            "2019-06-17 17:19:20,696 epoch 19 - iter 18/99 - loss 36.30657276\n",
            "2019-06-17 17:20:54,008 epoch 19 - iter 27/99 - loss 35.38773649\n",
            "2019-06-17 17:22:04,150 epoch 19 - iter 36/99 - loss 33.13925991\n",
            "2019-06-17 17:23:33,696 epoch 19 - iter 45/99 - loss 35.23775806\n",
            "2019-06-17 17:24:43,663 epoch 19 - iter 54/99 - loss 35.09930430\n",
            "2019-06-17 17:26:28,856 epoch 19 - iter 63/99 - loss 35.96878788\n",
            "2019-06-17 17:27:51,693 epoch 19 - iter 72/99 - loss 37.00906173\n",
            "2019-06-17 17:29:07,414 epoch 19 - iter 81/99 - loss 36.53590565\n",
            "2019-06-17 17:31:01,529 epoch 19 - iter 90/99 - loss 37.62922868\n",
            "2019-06-17 17:32:25,455 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:32:25,456 EPOCH 19 done: loss 37.8211 - lr 0.0250 - bad epochs 0\n",
            "2019-06-17 17:34:10,101 DEV : loss 34.975746154785156 - score 0.2029\n",
            "2019-06-17 17:38:02,104 TEST : loss 34.177520751953125 - score 0.2726\n",
            "2019-06-17 17:38:02,114 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:38:24,360 epoch 20 - iter 0/99 - loss 90.37947083\n",
            "2019-06-17 17:39:31,538 epoch 20 - iter 9/99 - loss 44.86242676\n",
            "2019-06-17 17:41:26,818 epoch 20 - iter 18/99 - loss 41.11987862\n",
            "2019-06-17 17:42:51,788 epoch 20 - iter 27/99 - loss 44.19868445\n",
            "2019-06-17 17:43:59,723 epoch 20 - iter 36/99 - loss 40.85248254\n",
            "2019-06-17 17:45:02,935 epoch 20 - iter 45/99 - loss 39.57539656\n",
            "2019-06-17 17:46:18,587 epoch 20 - iter 54/99 - loss 38.13972170\n",
            "2019-06-17 17:47:51,687 epoch 20 - iter 63/99 - loss 37.26690623\n",
            "2019-06-17 17:49:26,278 epoch 20 - iter 72/99 - loss 36.62526392\n",
            "2019-06-17 17:51:03,615 epoch 20 - iter 81/99 - loss 36.44222529\n",
            "2019-06-17 17:52:34,552 epoch 20 - iter 90/99 - loss 37.18520418\n",
            "2019-06-17 17:53:41,896 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:53:41,898 EPOCH 20 done: loss 36.9913 - lr 0.0250 - bad epochs 1\n",
            "2019-06-17 17:55:26,580 DEV : loss 32.76985549926758 - score 0.3604\n",
            "2019-06-17 17:59:18,797 TEST : loss 33.30589294433594 - score 0.4348\n",
            "2019-06-17 17:59:18,807 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 17:59:25,534 epoch 21 - iter 0/99 - loss 42.90108871\n",
            "2019-06-17 18:01:12,397 epoch 21 - iter 9/99 - loss 32.95873394\n",
            "2019-06-17 18:02:36,368 epoch 21 - iter 18/99 - loss 32.79687088\n",
            "2019-06-17 18:03:51,945 epoch 21 - iter 27/99 - loss 34.62177644\n",
            "2019-06-17 18:05:17,674 epoch 21 - iter 36/99 - loss 36.13061781\n",
            "2019-06-17 18:06:45,090 epoch 21 - iter 45/99 - loss 38.06598186\n",
            "2019-06-17 18:07:58,488 epoch 21 - iter 54/99 - loss 38.95705608\n",
            "2019-06-17 18:09:36,134 epoch 21 - iter 63/99 - loss 39.14384329\n",
            "2019-06-17 18:10:54,489 epoch 21 - iter 72/99 - loss 38.83818083\n",
            "2019-06-17 18:12:25,490 epoch 21 - iter 81/99 - loss 38.45688738\n",
            "2019-06-17 18:13:51,802 epoch 21 - iter 90/99 - loss 37.93128506\n",
            "2019-06-17 18:15:19,432 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 18:15:19,433 EPOCH 21 done: loss 37.0727 - lr 0.0250 - bad epochs 2\n",
            "2019-06-17 18:17:04,384 DEV : loss 33.00577163696289 - score 0.2417\n",
            "2019-06-17 18:20:56,420 TEST : loss 34.000118255615234 - score 0.4361\n",
            "2019-06-17 18:20:56,430 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 18:21:02,836 epoch 22 - iter 0/99 - loss 39.80808258\n",
            "2019-06-17 18:22:20,911 epoch 22 - iter 9/99 - loss 31.31211834\n",
            "2019-06-17 18:23:40,307 epoch 22 - iter 18/99 - loss 34.67384439\n",
            "2019-06-17 18:25:24,674 epoch 22 - iter 27/99 - loss 33.23639393\n",
            "2019-06-17 18:26:57,696 epoch 22 - iter 36/99 - loss 37.03362911\n",
            "2019-06-17 18:28:11,988 epoch 22 - iter 45/99 - loss 36.09344737\n",
            "2019-06-17 18:29:54,119 epoch 22 - iter 54/99 - loss 36.94774480\n",
            "2019-06-17 18:31:27,135 epoch 22 - iter 63/99 - loss 36.95850167\n",
            "2019-06-17 18:32:38,523 epoch 22 - iter 72/99 - loss 36.09088848\n",
            "2019-06-17 18:34:09,543 epoch 22 - iter 81/99 - loss 35.73012047\n",
            "2019-06-17 18:35:23,659 epoch 22 - iter 90/99 - loss 35.60301372\n",
            "2019-06-17 18:36:46,628 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 18:36:46,631 EPOCH 22 done: loss 36.2216 - lr 0.0250 - bad epochs 3\n",
            "2019-06-17 18:38:34,985 DEV : loss 32.84382247924805 - score 0.2346\n",
            "2019-06-17 18:42:27,791 TEST : loss 34.739707946777344 - score 0.4346\n",
            "Epoch    21: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-06-17 18:42:27,801 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 18:42:36,168 epoch 23 - iter 0/99 - loss 23.28223038\n",
            "2019-06-17 18:43:58,720 epoch 23 - iter 9/99 - loss 39.03277779\n",
            "2019-06-17 18:45:10,040 epoch 23 - iter 18/99 - loss 32.58672975\n",
            "2019-06-17 18:46:40,356 epoch 23 - iter 27/99 - loss 32.48505855\n",
            "2019-06-17 18:48:06,493 epoch 23 - iter 36/99 - loss 32.57703124\n",
            "2019-06-17 18:49:52,025 epoch 23 - iter 45/99 - loss 33.10964234\n",
            "2019-06-17 18:51:08,617 epoch 23 - iter 54/99 - loss 32.80333698\n",
            "2019-06-17 18:52:29,033 epoch 23 - iter 63/99 - loss 32.93303181\n",
            "2019-06-17 18:53:54,976 epoch 23 - iter 72/99 - loss 34.53001672\n",
            "2019-06-17 18:55:22,742 epoch 23 - iter 81/99 - loss 34.87490566\n",
            "2019-06-17 18:57:10,004 epoch 23 - iter 90/99 - loss 34.74202028\n",
            "2019-06-17 18:58:25,455 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 18:58:25,457 EPOCH 23 done: loss 34.8313 - lr 0.0125 - bad epochs 0\n",
            "2019-06-17 19:00:12,970 DEV : loss 32.704490661621094 - score 0.2159\n",
            "2019-06-17 19:04:05,429 TEST : loss 32.197532653808594 - score 0.3282\n",
            "2019-06-17 19:04:05,449 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 19:04:26,923 epoch 24 - iter 0/99 - loss 31.42626953\n",
            "2019-06-17 19:05:38,104 epoch 24 - iter 9/99 - loss 29.13191662\n",
            "2019-06-17 19:07:26,050 epoch 24 - iter 18/99 - loss 35.53005851\n",
            "2019-06-17 19:08:45,991 epoch 24 - iter 27/99 - loss 32.30848183\n",
            "2019-06-17 19:10:04,491 epoch 24 - iter 36/99 - loss 31.77468532\n",
            "2019-06-17 19:11:29,705 epoch 24 - iter 45/99 - loss 33.52639853\n",
            "2019-06-17 19:12:37,024 epoch 24 - iter 54/99 - loss 35.42835360\n",
            "2019-06-17 19:14:18,922 epoch 24 - iter 63/99 - loss 34.94951892\n",
            "2019-06-17 19:15:47,000 epoch 24 - iter 72/99 - loss 35.41499927\n",
            "2019-06-17 19:17:09,126 epoch 24 - iter 81/99 - loss 35.44158359\n",
            "2019-06-17 19:18:32,833 epoch 24 - iter 90/99 - loss 35.69409500\n",
            "2019-06-17 19:19:34,856 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 19:19:34,859 EPOCH 24 done: loss 35.2488 - lr 0.0125 - bad epochs 1\n",
            "2019-06-17 19:21:22,368 DEV : loss 32.29705810546875 - score 0.2193\n",
            "2019-06-17 19:25:14,536 TEST : loss 32.08259582519531 - score 0.2898\n",
            "2019-06-17 19:25:14,546 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 19:25:25,259 epoch 25 - iter 0/99 - loss 41.29035568\n",
            "2019-06-17 19:26:28,146 epoch 25 - iter 9/99 - loss 27.97133379\n",
            "2019-06-17 19:28:01,503 epoch 25 - iter 18/99 - loss 29.95790261\n",
            "2019-06-17 19:29:18,825 epoch 25 - iter 27/99 - loss 30.37895618\n",
            "2019-06-17 19:31:04,532 epoch 25 - iter 36/99 - loss 31.24028685\n",
            "2019-06-17 19:32:18,796 epoch 25 - iter 45/99 - loss 31.68514807\n",
            "2019-06-17 19:33:41,102 epoch 25 - iter 54/99 - loss 31.49065222\n",
            "2019-06-17 19:35:06,891 epoch 25 - iter 63/99 - loss 32.08354107\n",
            "2019-06-17 19:36:18,553 epoch 25 - iter 72/99 - loss 31.76451059\n",
            "2019-06-17 19:37:45,957 epoch 25 - iter 81/99 - loss 32.19907276\n",
            "2019-06-17 19:39:26,719 epoch 25 - iter 90/99 - loss 33.93579344\n",
            "2019-06-17 19:41:03,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 19:41:03,813 EPOCH 25 done: loss 34.1763 - lr 0.0125 - bad epochs 2\n",
            "2019-06-17 19:42:51,682 DEV : loss 31.0058650970459 - score 0.2996\n",
            "2019-06-17 19:46:44,112 TEST : loss 31.378307342529297 - score 0.4659\n",
            "2019-06-17 19:46:44,123 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 19:46:54,651 epoch 26 - iter 0/99 - loss 29.01598549\n",
            "2019-06-17 19:48:02,846 epoch 26 - iter 9/99 - loss 29.68329887\n",
            "2019-06-17 19:49:34,284 epoch 26 - iter 18/99 - loss 29.58482923\n",
            "2019-06-17 19:51:00,340 epoch 26 - iter 27/99 - loss 31.86134195\n",
            "2019-06-17 19:52:04,997 epoch 26 - iter 36/99 - loss 29.27192477\n",
            "2019-06-17 19:53:41,836 epoch 26 - iter 45/99 - loss 31.53300563\n",
            "2019-06-17 19:55:19,728 epoch 26 - iter 54/99 - loss 31.57885219\n",
            "2019-06-17 19:56:57,801 epoch 26 - iter 63/99 - loss 33.74084504\n",
            "2019-06-17 19:58:30,916 epoch 26 - iter 72/99 - loss 33.48623243\n",
            "2019-06-17 20:00:05,450 epoch 26 - iter 81/99 - loss 33.78289224\n",
            "2019-06-17 20:01:21,505 epoch 26 - iter 90/99 - loss 33.84660353\n",
            "2019-06-17 20:02:30,101 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:02:30,103 EPOCH 26 done: loss 33.7104 - lr 0.0125 - bad epochs 3\n",
            "2019-06-17 20:04:18,148 DEV : loss 31.874473571777344 - score 0.2263\n",
            "2019-06-17 20:08:08,282 TEST : loss 31.770998001098633 - score 0.2872\n",
            "Epoch    25: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-06-17 20:08:08,293 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:08:32,233 epoch 27 - iter 0/99 - loss 21.03787804\n",
            "2019-06-17 20:09:57,525 epoch 27 - iter 9/99 - loss 25.72173166\n",
            "2019-06-17 20:11:13,692 epoch 27 - iter 18/99 - loss 30.94913101\n",
            "2019-06-17 20:12:31,515 epoch 27 - iter 27/99 - loss 30.31167589\n",
            "2019-06-17 20:14:00,226 epoch 27 - iter 36/99 - loss 33.08624278\n",
            "2019-06-17 20:15:39,628 epoch 27 - iter 45/99 - loss 32.48895815\n",
            "2019-06-17 20:17:25,817 epoch 27 - iter 54/99 - loss 33.03761378\n",
            "2019-06-17 20:18:43,552 epoch 27 - iter 63/99 - loss 33.22532973\n",
            "2019-06-17 20:20:14,209 epoch 27 - iter 72/99 - loss 33.01139382\n",
            "2019-06-17 20:21:48,529 epoch 27 - iter 81/99 - loss 32.91984923\n",
            "2019-06-17 20:23:11,247 epoch 27 - iter 90/99 - loss 33.39266458\n",
            "2019-06-17 20:24:29,904 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:24:29,906 EPOCH 27 done: loss 33.7044 - lr 0.0063 - bad epochs 0\n",
            "2019-06-17 20:26:18,217 DEV : loss 30.876420974731445 - score 0.2222\n",
            "2019-06-17 20:30:08,002 TEST : loss 31.439136505126953 - score 0.4519\n",
            "2019-06-17 20:30:08,011 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:30:14,483 epoch 28 - iter 0/99 - loss 17.68655396\n",
            "2019-06-17 20:31:25,380 epoch 28 - iter 9/99 - loss 25.81537695\n",
            "2019-06-17 20:33:00,443 epoch 28 - iter 18/99 - loss 27.97237221\n",
            "2019-06-17 20:34:11,188 epoch 28 - iter 27/99 - loss 26.71803876\n",
            "2019-06-17 20:35:17,849 epoch 28 - iter 36/99 - loss 29.27335682\n",
            "2019-06-17 20:36:41,619 epoch 28 - iter 45/99 - loss 29.12577065\n",
            "2019-06-17 20:38:21,094 epoch 28 - iter 54/99 - loss 29.31963602\n",
            "2019-06-17 20:39:43,605 epoch 28 - iter 63/99 - loss 30.96625820\n",
            "2019-06-17 20:41:25,573 epoch 28 - iter 72/99 - loss 31.68461878\n",
            "2019-06-17 20:42:49,952 epoch 28 - iter 81/99 - loss 32.01797913\n",
            "2019-06-17 20:44:05,221 epoch 28 - iter 90/99 - loss 31.89007118\n",
            "2019-06-17 20:45:37,815 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:45:37,820 EPOCH 28 done: loss 33.3947 - lr 0.0063 - bad epochs 1\n",
            "2019-06-17 20:47:25,665 DEV : loss 30.48183250427246 - score 0.2243\n",
            "2019-06-17 20:51:15,776 TEST : loss 31.071247100830078 - score 0.4543\n",
            "2019-06-17 20:51:15,786 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 20:51:27,286 epoch 29 - iter 0/99 - loss 18.62661171\n",
            "2019-06-17 20:52:30,652 epoch 29 - iter 9/99 - loss 21.00277452\n",
            "2019-06-17 20:53:46,267 epoch 29 - iter 18/99 - loss 26.20429702\n",
            "2019-06-17 20:55:41,569 epoch 29 - iter 27/99 - loss 28.53545822\n",
            "2019-06-17 20:56:45,906 epoch 29 - iter 36/99 - loss 26.56357938\n",
            "2019-06-17 20:58:19,289 epoch 29 - iter 45/99 - loss 28.88555143\n",
            "2019-06-17 20:59:33,581 epoch 29 - iter 54/99 - loss 29.39265724\n",
            "2019-06-17 21:01:02,918 epoch 29 - iter 63/99 - loss 30.20468255\n",
            "2019-06-17 21:02:38,050 epoch 29 - iter 72/99 - loss 31.47606226\n",
            "2019-06-17 21:04:11,210 epoch 29 - iter 81/99 - loss 32.42008006\n",
            "2019-06-17 21:05:33,826 epoch 29 - iter 90/99 - loss 33.16871248\n",
            "2019-06-17 21:06:59,049 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:06:59,051 EPOCH 29 done: loss 33.1697 - lr 0.0063 - bad epochs 2\n",
            "2019-06-17 21:08:46,812 DEV : loss 30.995872497558594 - score 0.1975\n",
            "2019-06-17 21:12:36,807 TEST : loss 31.948793411254883 - score 0.2853\n",
            "2019-06-17 21:12:36,817 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:12:49,611 epoch 30 - iter 0/99 - loss 33.01020432\n",
            "2019-06-17 21:14:05,123 epoch 30 - iter 9/99 - loss 30.06126938\n",
            "2019-06-17 21:15:01,153 epoch 30 - iter 18/99 - loss 29.19432103\n",
            "2019-06-17 21:16:32,750 epoch 30 - iter 27/99 - loss 32.30708023\n",
            "2019-06-17 21:17:49,848 epoch 30 - iter 36/99 - loss 32.49218216\n",
            "2019-06-17 21:19:05,579 epoch 30 - iter 45/99 - loss 32.65148530\n",
            "2019-06-17 21:20:21,558 epoch 30 - iter 54/99 - loss 32.38556180\n",
            "2019-06-17 21:21:51,106 epoch 30 - iter 63/99 - loss 32.98163934\n",
            "2019-06-17 21:23:32,308 epoch 30 - iter 72/99 - loss 32.85622149\n",
            "2019-06-17 21:25:19,354 epoch 30 - iter 81/99 - loss 32.57734061\n",
            "2019-06-17 21:27:08,848 epoch 30 - iter 90/99 - loss 32.21282285\n",
            "2019-06-17 21:28:33,754 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:28:33,756 EPOCH 30 done: loss 32.9293 - lr 0.0063 - bad epochs 3\n",
            "2019-06-17 21:30:21,833 DEV : loss 29.92860984802246 - score 0.2878\n",
            "2019-06-17 21:34:11,750 TEST : loss 30.772615432739258 - score 0.4667\n",
            "Epoch    29: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-06-17 21:34:11,760 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:34:30,788 epoch 31 - iter 0/99 - loss 69.25466156\n",
            "2019-06-17 21:36:08,299 epoch 31 - iter 9/99 - loss 42.28347473\n",
            "2019-06-17 21:37:20,576 epoch 31 - iter 18/99 - loss 39.40290722\n",
            "2019-06-17 21:38:52,296 epoch 31 - iter 27/99 - loss 36.59677400\n",
            "2019-06-17 21:40:03,300 epoch 31 - iter 36/99 - loss 35.24618981\n",
            "2019-06-17 21:41:36,316 epoch 31 - iter 45/99 - loss 35.37587259\n",
            "2019-06-17 21:42:53,436 epoch 31 - iter 54/99 - loss 34.84210110\n",
            "2019-06-17 21:44:20,051 epoch 31 - iter 63/99 - loss 33.86349846\n",
            "2019-06-17 21:46:04,872 epoch 31 - iter 72/99 - loss 33.05661294\n",
            "2019-06-17 21:47:36,024 epoch 31 - iter 81/99 - loss 33.59306066\n",
            "2019-06-17 21:49:00,924 epoch 31 - iter 90/99 - loss 33.20985175\n",
            "2019-06-17 21:50:09,968 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:50:09,970 EPOCH 31 done: loss 32.6809 - lr 0.0031 - bad epochs 0\n",
            "2019-06-17 21:51:54,891 DEV : loss 30.235570907592773 - score 0.2168\n",
            "2019-06-17 21:55:47,067 TEST : loss 30.954978942871094 - score 0.4552\n",
            "2019-06-17 21:55:47,077 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 21:55:55,254 epoch 32 - iter 0/99 - loss 25.90058708\n",
            "2019-06-17 21:57:06,332 epoch 32 - iter 9/99 - loss 34.73706665\n",
            "2019-06-17 21:58:11,333 epoch 32 - iter 18/99 - loss 32.36280577\n",
            "2019-06-17 21:59:54,336 epoch 32 - iter 27/99 - loss 32.18991780\n",
            "2019-06-17 22:01:18,570 epoch 32 - iter 36/99 - loss 31.88634635\n",
            "2019-06-17 22:02:54,997 epoch 32 - iter 45/99 - loss 32.06735250\n",
            "2019-06-17 22:04:46,546 epoch 32 - iter 54/99 - loss 31.50761058\n",
            "2019-06-17 22:06:15,917 epoch 32 - iter 63/99 - loss 31.53918464\n",
            "2019-06-17 22:07:44,686 epoch 32 - iter 72/99 - loss 33.26802378\n",
            "2019-06-17 22:09:08,051 epoch 32 - iter 81/99 - loss 32.46408208\n",
            "2019-06-17 22:10:43,132 epoch 32 - iter 90/99 - loss 32.41082510\n",
            "2019-06-17 22:11:50,014 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 22:11:50,016 EPOCH 32 done: loss 32.7488 - lr 0.0031 - bad epochs 1\n",
            "2019-06-17 22:13:35,186 DEV : loss 29.835369110107422 - score 0.2725\n",
            "2019-06-17 22:17:30,461 TEST : loss 31.149988174438477 - score 0.4697\n",
            "2019-06-17 22:17:30,471 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 22:17:43,186 epoch 33 - iter 0/99 - loss 27.88564491\n",
            "2019-06-17 22:19:10,849 epoch 33 - iter 9/99 - loss 33.34875212\n",
            "2019-06-17 22:20:23,724 epoch 33 - iter 18/99 - loss 29.83746238\n",
            "2019-06-17 22:21:31,116 epoch 33 - iter 27/99 - loss 30.82078900\n",
            "2019-06-17 22:22:51,293 epoch 33 - iter 36/99 - loss 29.40603803\n",
            "2019-06-17 22:24:16,036 epoch 33 - iter 45/99 - loss 29.16621896\n",
            "2019-06-17 22:25:29,753 epoch 33 - iter 54/99 - loss 29.56081692\n",
            "2019-06-17 22:26:43,249 epoch 33 - iter 63/99 - loss 30.70235017\n",
            "2019-06-17 22:28:19,079 epoch 33 - iter 72/99 - loss 30.54833255\n",
            "2019-06-17 22:29:50,822 epoch 33 - iter 81/99 - loss 30.67661502\n",
            "2019-06-17 22:31:42,139 epoch 33 - iter 90/99 - loss 31.98358506\n",
            "2019-06-17 22:33:15,422 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 22:33:15,424 EPOCH 33 done: loss 32.2085 - lr 0.0031 - bad epochs 2\n",
            "2019-06-17 22:35:01,721 DEV : loss 30.03757095336914 - score 0.267\n",
            "2019-06-17 22:38:57,193 TEST : loss 30.883249282836914 - score 0.45\n",
            "2019-06-17 22:38:57,204 ----------------------------------------------------------------------------------------------------\n",
            "2019-06-17 22:39:06,653 epoch 34 - iter 0/99 - loss 23.96971512\n",
            "2019-06-17 22:40:15,196 epoch 34 - iter 9/99 - loss 25.14567308\n",
            "2019-06-17 22:41:44,069 epoch 34 - iter 18/99 - loss 27.87721132\n",
            "2019-06-17 22:43:00,760 epoch 34 - iter 27/99 - loss 28.63489011\n",
            "2019-06-17 22:44:17,297 epoch 34 - iter 36/99 - loss 33.27946501\n",
            "2019-06-17 22:45:53,390 epoch 34 - iter 45/99 - loss 32.16319445\n",
            "2019-06-17 22:47:25,514 epoch 34 - iter 54/99 - loss 31.82725293\n",
            "2019-06-17 22:48:47,602 epoch 34 - iter 63/99 - loss 32.63939396\n",
            "2019-06-17 22:50:45,289 epoch 34 - iter 72/99 - loss 32.31980670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCS2pbH9mn4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaJu3kgcG2sI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}